{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f070def",
   "metadata": {},
   "source": [
    "# shared utilities for all the Phase-Diff models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669f8da7",
   "metadata": {},
   "source": [
    "### Imports & global config helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchaudio\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 7):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class STFTCfg:\n",
    "    def __init__(self, sr=16000, n_fft=512, hop=80, win_length=None):\n",
    "        self.sr = int(sr)\n",
    "        self.n_fft = int(n_fft)\n",
    "        self.hop = int(hop)\n",
    "        self.win_length = int(win_length or n_fft)\n",
    "\n",
    "    def to_json(self) -> str:\n",
    "        return json.dumps({\"sr\": self.sr, \"n_fft\": self.n_fft, \"hop\": self.hop})\n",
    "\n",
    "    @staticmethod\n",
    "    def from_json(s: str) -> \"STFTCfg\":\n",
    "        obj = json.loads(s)\n",
    "        return STFTCfg(obj[\"sr\"], obj[\"n_fft\"], obj[\"hop\"], obj[\"n_fft\"])\n",
    "\n",
    "def assert_same_cfg(a: STFTCfg, b: STFTCfg):\n",
    "    assert (a.n_fft, a.hop, a.win_length) == (b.n_fft, b.hop, b.win_length), \\\n",
    "        f\"STFT params differ: {(a.n_fft,a.hop,a.win_length)} vs {(b.n_fft,b.hop,b.win_length)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80e34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd940816",
   "metadata": {},
   "source": [
    "### Causal STFT / ISTFT (√Hann dual windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Strictly-causal STFT: center=False and a single *left* pad so the very first\n",
    "    frame has a full window. √Hann analysis window.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_fft: int, hop_length: int, win_length: int, window_type=\"sqrt_hann\"):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "\n",
    "        if window_type == \"sqrt_hann\":\n",
    "            w = torch.sqrt(torch.hann_window(win_length))\n",
    "        elif window_type == \"hann\":\n",
    "            w = torch.hann_window(win_length)\n",
    "        elif window_type == \"rectangular\":\n",
    "            w = torch.ones(win_length)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid window type: {window_type}\")\n",
    "        self.register_buffer(\"window\", w)\n",
    "        self.left_pad = max(0, win_length - hop_length)\n",
    "\n",
    "    def forward(self, wav: torch.Tensor) -> torch.Tensor:\n",
    "        # wav: (B, L)\n",
    "        if wav.dim() != 2: raise ValueError(\"wav must be (B, L)\")\n",
    "        if self.left_pad:\n",
    "            wav = tF.pad(wav, (self.left_pad, 0))\n",
    "        return torch.stft(\n",
    "            wav, n_fft=self.n_fft, hop_length=self.hop_length, win_length=self.win_length,\n",
    "            window=self.window.to(wav.device), center=False, return_complex=True\n",
    "        )\n",
    "\n",
    "\n",
    "class CausalISTFT(nn.Module):\n",
    "    \"\"\"\n",
    "    Dual of the CausalSTFT above (√Hann synthesis). Strictly causal OLA.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_fft: int, hop_length: int, win_length: int):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        self.register_buffer(\"window\", torch.sqrt(torch.hann_window(win_length)))\n",
    "        self.left_pad = max(0, win_length - hop_length)\n",
    "\n",
    "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
    "        # spec: (B, F, T) complex, F = n_fft//2+1\n",
    "        if spec.dim() != 3: raise ValueError(\"spec must be (B, F, T) complex\")\n",
    "        B, F, T = spec.shape\n",
    "\n",
    "        time_frames = torch.fft.irfft(spec, n=self.n_fft, dim=1, norm=\"backward\")\n",
    "        time_frames = time_frames * self.window[None, :, None]\n",
    "\n",
    "        out_len = (T - 1) * self.hop_length + self.win_length\n",
    "        wav = tF.fold(\n",
    "            time_frames, output_size=(1, out_len),\n",
    "            kernel_size=(1, self.win_length), stride=(1, self.hop_length)\n",
    "        )[:, 0, 0]  # (B, out_len)\n",
    "\n",
    "        if self.left_pad:\n",
    "            wav = wav[..., self.left_pad:]\n",
    "\n",
    "        # window envelope normalization\n",
    "        w2 = self.window.square().expand(1, T, -1).transpose(1, 2)\n",
    "        env = tF.fold(\n",
    "            w2, output_size=(1, out_len),\n",
    "            kernel_size=(1, self.win_length), stride=(1, self.hop_length)\n",
    "        ).squeeze()\n",
    "        if self.left_pad:\n",
    "            env = env[self.left_pad:]\n",
    "        env = env.clamp_min(1e-3)\n",
    "        return wav / env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d50230",
   "metadata": {},
   "source": [
    "### Angle utilities and also phase-diff conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f486032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(ang: torch.Tensor, ste: bool = False) -> torch.Tensor:\n",
    "    out = torch.remainder(ang + math.pi, 2 * math.pi) - math.pi\n",
    "    if ste:\n",
    "        out = ang + (out - ang).detach()\n",
    "    return out\n",
    "\n",
    "def bpd_to_tpd(bpd: torch.Tensor, n_fft: int, hop_length: int, keep_first_frame: bool = False, squeeze: bool = True) -> torch.Tensor:\n",
    "    if bpd.ndim == 2:\n",
    "        bpd = bpd.unsqueeze(0); added_batch = True\n",
    "    else:\n",
    "        added_batch = False\n",
    "    B, F, T = bpd.shape\n",
    "    m = torch.arange(F, device=bpd.device).view(1, F, 1)\n",
    "    bias = 2 * math.pi * hop_length * m / n_fft\n",
    "    phi = bpd[:, :, 1:] + bias\n",
    "    core = wrap(phi, ste=True)\n",
    "    tpd = torch.cat([torch.zeros_like(core[:, :, :1]), core], dim=2) if keep_first_frame else core\n",
    "    if added_batch and squeeze:\n",
    "        tpd = tpd.squeeze(0)\n",
    "    return tpd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efda1d4",
   "metadata": {},
   "source": [
    "### Dataset-agnostic targets (mag, FPD, BPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b81fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_mag_fpd_bpd(\n",
    "    wav: torch.Tensor, n_fft: int, hop: int, stft_mod: CausalSTFT\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    wav: (B, L) -> mag (B,F,T), fpd (B,F-1,T), bpd (B,F,T)\n",
    "    \"\"\"\n",
    "    S = stft_mod(wav)                    # (B, F, T) complex\n",
    "    phase = torch.angle(S)               # (B, F, T)\n",
    "    mag = S.abs().clamp_min(1e-8)\n",
    "\n",
    "    fpd = wrap(phase[:, 1:, :] - phase[:, :-1, :])\n",
    "    tpd = torch.zeros_like(phase)\n",
    "    tpd[:, :, 1:] = wrap(phase[:, :, 1:] - phase[:, :, :-1])\n",
    "\n",
    "    B, F, T = phase.shape\n",
    "    m = torch.arange(F, device=phase.device).view(1, F, 1)\n",
    "    bpd = wrap(tpd - 2 * math.pi * hop * m / n_fft)\n",
    "    return mag, fpd, bpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@no_grad()\n",
    "def pv_time_stretch(\n",
    "    wav: Tensor,\n",
    "    n_fft: int,\n",
    "    hop_length: int,\n",
    "    rate: float,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Phase-vocoder time-stretch (pitch-preserving) using torchaudio.transforms.TimeStretch.\n",
    "\n",
    "    wav : (B, N) or (N,) mono tensor\n",
    "    rate: >1.0 -> slower, <1.0 -> faster\n",
    "\n",
    "    Returns:\n",
    "        wav_out: (B, N_out) stretched waveform at the SAME sample rate\n",
    "    \"\"\"\n",
    "    # Ensure (B, N)\n",
    "    if wav.dim() == 1:\n",
    "        wav = wav.unsqueeze(0)\n",
    "    assert wav.dim() == 2, f\"Expected 2D (B,N) wav, got {wav.shape}\"\n",
    "\n",
    "    B, N = wav.shape\n",
    "    device = wav.device\n",
    "\n",
    "    window = torch.hann_window(n_fft, device=device)\n",
    "\n",
    "    # 1) STFT: (B, F, T) complex\n",
    "    spec = torch.stft(\n",
    "        wav,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=n_fft,\n",
    "        window=window,\n",
    "        center=True,\n",
    "        return_complex=True,\n",
    "    )  # (B, F, T)\n",
    "\n",
    "    # 2) View as real for TimeStretch: (B, F, T, 2)\n",
    "    spec_ri = torch.view_as_real(spec)\n",
    "    n_freq = spec_ri.shape[1]  # this is the TRUE F\n",
    "\n",
    "    # 3) TimeStretch handles phase_advance internally, no manual phase_vocoder\n",
    "    ts = torchaudio.transforms.TimeStretch(\n",
    "        hop_length=hop_length,\n",
    "        n_freq=n_freq,\n",
    "        fixed_rate=rate,\n",
    "    ).to(device)\n",
    "\n",
    "    spec_stretch_ri = ts(spec_ri)            # (B, F, T', 2)\n",
    "    spec_stretch = torch.view_as_complex(spec_stretch_ri)  # (B, F, T')\n",
    "\n",
    "    # 4) ISTFT back to waveform. Length scales ~ rate\n",
    "    N_out = int(math.ceil(N * rate))\n",
    "    wav_out = torch.istft(\n",
    "        spec_stretch,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=n_fft,\n",
    "        window=window,\n",
    "        center=True,\n",
    "        length=N_out,\n",
    "    )  # (B, N_out)\n",
    "\n",
    "    return wav_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea533094",
   "metadata": {},
   "source": [
    "### Waveform reconstruction from mag + (FPD,TPD) or (FPD,BPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a929a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def solve_tridiag_cpu(lower: torch.Tensor, diag: torch.Tensor, upper: torch.Tensor, rhs: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    CPU solve for Hermitian tridiagonal system using SciPy if available,\n",
    "    otherwise a generic banded solve via torch.linalg for small sizes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import scipy.linalg as la\n",
    "        n = diag.numel()\n",
    "        ab = torch.empty((3, n), dtype=diag.dtype)\n",
    "        ab[0, 1:] = upper; ab[0, 0] = 0\n",
    "        ab[1, :]  = diag\n",
    "        ab[2, :-1] = lower; ab[2, -1] = 0\n",
    "        x_np = la.solve_banded((1, 1), ab.numpy(), rhs.numpy(), overwrite_ab=False, overwrite_b=False)\n",
    "        return torch.as_tensor(x_np, dtype=rhs.dtype, device=rhs.device)\n",
    "    except Exception:\n",
    "        # \n",
    "        # \n",
    "        F = diag.numel()\n",
    "        a = lower.clone().cpu().numpy()\n",
    "        b = diag.clone().cpu().numpy()\n",
    "        c = upper.clone().cpu().numpy()\n",
    "        d = rhs .clone().cpu().numpy()\n",
    "        # forward sweep\n",
    "        for i in range(1, F):\n",
    "            w = a[i-1] / b[i-1]\n",
    "            b[i] = b[i] - w * c[i-1]\n",
    "            d[i] = d[i] - w * d[i-1]\n",
    "        x = d\n",
    "        x[-1] = x[-1] / b[-1]\n",
    "        for i in range(F-2, -1, -1):\n",
    "            x[i] = (x[i] - c[i] * x[i+1]) / b[i]\n",
    "        return torch.as_tensor(x, dtype=rhs.dtype, device=rhs.device)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mag_fpd_tpd_to_waveform(mag: torch.Tensor, fpd: torch.Tensor, tpd: torch.Tensor, n_fft: int, hop_length: int, eps: float = 1e-8, squeeze: bool = False) -> torch.Tensor:\n",
    "    if mag.ndim == 2:\n",
    "        mag, fpd, tpd = mag.unsqueeze(0), fpd.unsqueeze(0), tpd.unsqueeze(0)\n",
    "    B, F, T = mag.shape\n",
    "    device = mag.device\n",
    "    stft_hat = torch.zeros((B, F, T), dtype=torch.complex64, device=device)\n",
    "\n",
    "    # t=0 from cumulative FPD\n",
    "    phase_f0 = torch.zeros((B, F), device=device)\n",
    "    phase_f0[:, 1:] = torch.cumsum(fpd[:, :, 0], dim=1)\n",
    "    stft_hat[:, :, 0] = mag[:, :, 0] * torch.exp(1j * phase_f0)\n",
    "\n",
    "    for t in range(1, T):\n",
    "        Y_prev = stft_hat[:, :, t - 1]\n",
    "        ratio_u = (mag[:, 1:, t] / (mag[:, :-1, t] + eps)) * torch.exp(1j * fpd[:, :, t])  # (B, F-1)\n",
    "        ratio_v = (mag[:, :,  t] / (mag[:, :,  t-1] + eps)) * torch.exp(1j * tpd[:, :, t]) # (B, F)\n",
    "\n",
    "        abs_u_sq = ratio_u.abs().square()\n",
    "        diag = torch.ones((B, F), dtype=torch.complex64, device=device)\n",
    "        diag[:, 0] += abs_u_sq[:, 0]\n",
    "        diag[:, 1:-1] += abs_u_sq[:, 1:] + 1\n",
    "        diag[:, -1] += 1\n",
    "\n",
    "        lower = -ratio_u.clone()         # (B, F-1)\n",
    "        upper = -ratio_u.conj()          # (B, F-1)\n",
    "        rhs = Y_prev * ratio_v           # (B, F)\n",
    "\n",
    "        z = torch.empty_like(rhs)\n",
    "        for b in range(B):\n",
    "            z[b] = solve_tridiag_cpu(lower[b].cpu(), diag[b].cpu(), upper[b].cpu(), rhs[b].cpu())\n",
    "        stft_hat[:, :, t] = mag[:, :, t] * torch.exp(1j * torch.angle(z))\n",
    "\n",
    "    istft = CausalISTFT(n_fft, hop_length, n_fft).to(device)\n",
    "    y = istft(stft_hat)\n",
    "    if squeeze and y.shape[0] == 1:\n",
    "        y = y.squeeze(0)\n",
    "    return y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def mag_fpd_bpd_to_waveform(mag: torch.Tensor, fpd: torch.Tensor, bpd: torch.Tensor, n_fft: int, hop_length: int) -> torch.Tensor:\n",
    "    tpd = bpd_to_tpd(bpd, n_fft=n_fft, hop_length=hop_length, keep_first_frame=True)\n",
    "    return mag_fpd_tpd_to_waveform(mag, fpd, tpd, n_fft=n_fft, hop_length=hop_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33011f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inpaint_k_between_pairs_linear(mag: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Replace k intermediate frames between anchors with linear blends, keeping T fixed.\n",
    "    mag: (B, F, T) linear magnitude\n",
    "    For k=1: replace indices 1,3,5,... with 0.5*(left+right)\n",
    "    For k=2: replace indices 1 and 2 in each block of 3 with 1/3 and 2/3 blends.\n",
    "    \"\"\"\n",
    "    if k <= 0:\n",
    "        return mag\n",
    "\n",
    "    B, F, T = mag.shape\n",
    "    step = k + 1\n",
    "    out = mag.clone()\n",
    "\n",
    "    # Walk in steps of (k+1), blending the k frames in between the endpoints\n",
    "    for left in range(0, T - step, step):\n",
    "        right = left + step\n",
    "        for j in range(1, step):\n",
    "            t = left + j\n",
    "            alpha = j / float(step)\n",
    "            out[:, :, t] = (1.0 - alpha) * mag[:, :, left] + alpha * mag[:, :, right]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa0047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- small conv stack w/ causal time padding ---\n",
    "\n",
    "def _causal_pad(x, k_f, k_t):\n",
    "    pad_t = (k_t - 1, 0)\n",
    "    pad_f = (k_f // 2, k_f // 2)\n",
    "    return tF.pad(x, pad_t + pad_f, mode=\"constant\", value=0.0)\n",
    "\n",
    "class CausalConv2d(nn.Module):\n",
    "    def __init__(self, Cin, Cout, k_f, k_t, stride_t=1, groups=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.k_f, self.k_t = k_f, k_t\n",
    "        self.conv = weight_norm(\n",
    "            nn.Conv2d(Cin, Cout, kernel_size=(k_f, k_t), stride=(1, stride_t), padding=0, groups=groups, bias=bias)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = _causal_pad(x, self.k_f, self.k_t)\n",
    "        return self.conv(x)\n",
    "\n",
    "class FreqGatedConv(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int, k_f: int, k_t: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = CausalConv2d(in_ch, out_ch, k_f=k_f, k_t=k_t)\n",
    "        self.conv2 = CausalConv2d(in_ch, out_ch, k_f=k_f, k_t=k_t)\n",
    "    def forward(self, x):\n",
    "        return self.conv1(x) * torch.sigmoid(self.conv2(x))\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self, in_ch: int, bn: bool = False):\n",
    "        super().__init__()\n",
    "        self.net1 = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_ch) if bn else nn.Identity(),\n",
    "            CausalConv2d(in_ch, 50, k_f=3, k_t=4, stride_t=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "        )\n",
    "        self.net2 = FreqGatedConv(50, 10, k_f=1, k_t=1)\n",
    "        self.norm = nn.BatchNorm2d(10) if bn else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(self.net2(self.net1(x)))\n",
    "\n",
    "class BodyBlock(nn.Module):\n",
    "    def __init__(self, dim, k_f=1, k_t=1, stride_t=1, bn=False):\n",
    "        super().__init__()\n",
    "        if k_t > 1:\n",
    "            conv = CausalConv2d(dim, dim, k_f=k_f, k_t=k_t, stride_t=stride_t)\n",
    "        else:\n",
    "            conv = weight_norm(nn.Conv2d(dim, dim, kernel_size=(k_f, 1), stride=(1, stride_t), padding=((k_f - 1)//2, 0)))\n",
    "        self.block = nn.Sequential(conv, nn.BatchNorm2d(dim) if bn else nn.Identity(), nn.LeakyReLU(0.1, inplace=True))\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class Body(nn.Module):\n",
    "    def __init__(self, dim=10, depth=5, k_f=1, k_t=1, stride_t=1, bn=False, use_film=False, film_scale=0.05):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([BodyBlock(dim, k_f=k_f, k_t=k_t, stride_t=stride_t, bn=bn) for _ in range(depth)])\n",
    "        self.norm = nn.BatchNorm2d(dim) if bn else nn.Identity()\n",
    "        self.use_film = use_film\n",
    "        # self.film = FiLM(dim, hidden=64, scale=film_scale) if use_film else None\n",
    "        self.film = FiLM(dim, hidden=64, strength=film_scale) if use_film else None\n",
    "\n",
    "    def forward(self, x, z=None):\n",
    "        feats = []\n",
    "        for blk in self.layers:\n",
    "            y = blk(x)\n",
    "            if self.use_film and (z is not None):\n",
    "                y = y + self.film(y, z)\n",
    "            x = x + y\n",
    "            feats.append(x)\n",
    "        return self.norm(x), feats\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, out_per_target: int):\n",
    "        super().__init__()\n",
    "        self.pre = FreqGatedConv(20, 50, k_f=3, k_t=1)\n",
    "        self.out_bpd = weight_norm(nn.Conv2d(50, out_per_target, kernel_size=1))\n",
    "        self.out_fpd = weight_norm(nn.Conv2d(50, out_per_target, kernel_size=1))\n",
    "    def forward(self, x):\n",
    "        h = self.pre(x)\n",
    "        return self.out_bpd(h), self.out_fpd(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8494b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseDiffPredictionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Single class for Baseline.\n",
    "    Expects input magnitude as log10(|S|)/6 folded to (B,2,F/2,T) internally.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_fft: int, hop_length: int, freq_fold_size: int = 2, bn: bool = False, use_film: bool = False):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.freq_fold_size = freq_fold_size\n",
    "        self.use_film = use_film\n",
    "\n",
    "        self.stft = CausalSTFT(n_fft, hop_length, n_fft)\n",
    "        self.stem_mag = Stem(in_ch=freq_fold_size, bn=bn)\n",
    "        self.stem_merge = nn.Conv2d(10, 10, kernel_size=1)\n",
    "\n",
    "        #\n",
    "        self.body = Body(bn=bn, use_film=False)\n",
    "        self.head = Head(out_per_target=freq_fold_size)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Conv1d, nn.Linear)):\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, *, wav: Optional[torch.Tensor] = None, mag: Optional[torch.Tensor] = None, cond_z: Optional[torch.Tensor] = None):\n",
    "        fmaps = []  # we don't use them during training, i can therfore keep emptyy\n",
    "\n",
    "        if (wav is None) == (mag is None):\n",
    "            raise ValueError(\"Provide either wav OR mag\")\n",
    "\n",
    "        if wav is not None:\n",
    "            mag_log = self.stft(wav).abs().clamp_min(1e-6).log10().unsqueeze(1) / 6.0  # (B,1,F,T)\n",
    "        else:\n",
    "            mag_log = mag.clamp_min(1e-6).log10().unsqueeze(1) / 6.0\n",
    "\n",
    "        # Fold frequency bins into 'channels' = freq_fold_size\n",
    "        mag_log = mag_log[:, :, :-1, :]                                   # drop Nyquist for even split\n",
    "        mag_log = rearrange(mag_log, 'b 1 (f n) t -> b n f t', n=self.freq_fold_size)\n",
    "\n",
    "        z0 = self.stem_mag(mag_log)                                       # (B,10,F,T)\n",
    "\n",
    "        if self.use_film:\n",
    "            if cond_z is None:\n",
    "                cond_z = torch.ones(z0.size(0), device=z0.device)\n",
    "            z0 = self.film_stem(z0, norm_z(cond_z))\n",
    "\n",
    "        z1, _ = self.body(z0)                                             # (B,10,F,T)\n",
    "        z = torch.cat([z0, z1], dim=1)                                    # (B,20,F,T)\n",
    "        bpd, fpd = self.head(z)                                           # (B,2,F',T)\n",
    "\n",
    "      \n",
    "        # Unfold to (B, F_flat, T)\n",
    "        bpd = rearrange(bpd, 'b n f t -> b (f n) t')  # expect F_flat == (F_in-1)\n",
    "        fpd = rearrange(fpd, 'b n f t -> b (f n) t')\n",
    "\n",
    "\n",
    "        F_in  = mag_log.shape[2] * self.freq_fold_size + 1  # add Nyquist we dropped\n",
    "        F_fpd = F_in - 1\n",
    "\n",
    "\n",
    "        # Make bpd exactly F_in by duplicating the last bin if needed\n",
    "        if bpd.size(1) < F_in:\n",
    "            bpd = torch.cat([bpd, bpd[:, -1:, :]], dim=1)\n",
    "        elif bpd.size(1) > F_in:\n",
    "            bpd = bpd[:, :F_in, :]\n",
    "\n",
    "        # Make fpd exactly F_in-1\n",
    "        if fpd.size(1) < F_fpd:\n",
    "            fpd = torch.cat([fpd, fpd[:, -1:, :]], dim=1)\n",
    "        elif fpd.size(1) > F_fpd:\n",
    "            fpd = fpd[:, :F_fpd, :]\n",
    "\n",
    "        return fpd, bpd, fmaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401efabe",
   "metadata": {},
   "source": [
    "## loss and simple stretching helper (log-mag bilinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eee0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vm_loss(target_rad: torch.Tensor, pred_rad: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Von–Mises / negative cosine loss on angles (same shape tensors, radians).\"\"\"\n",
    "    return -(torch.cos(target_rad - pred_rad)).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def stretch_logmag(mag: torch.Tensor, factor: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Stretch along time in log-magnitude using bilinear interpolation, then return to linear.\n",
    "    mag: (B, F, T) linear amplitude\n",
    "    \"\"\"\n",
    "    logmag = mag.clamp_min(1e-8).log10().unsqueeze(1)  # (B,1,F,T)\n",
    "    logmag_s = tF.interpolate(logmag, scale_factor=(1.0, factor), mode=\"bilinear\", align_corners=False).squeeze(1)\n",
    "    return (10**logmag_s).clamp_min(1e-8)\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def logmag_stretch_then_match_T(mag: torch.Tensor, factor: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Stretch magnitude in log-domain along time by `factor`, then resample\n",
    "    back to the original T so targets still align. Shape stays (B,F,T).\n",
    "    \"\"\"\n",
    "    B, Freq, T = mag.shape\n",
    "    logmag = mag.clamp_min(1e-8).log10().unsqueeze(1)            # (B,1,F,T)\n",
    "    stretched = tF.interpolate(logmag, scale_factor=(1.0, factor),\n",
    "                               mode=\"bilinear\", align_corners=False).squeeze(1)     # (B,F,T')\n",
    "    matched   = tF.interpolate(stretched.unsqueeze(1), size=(Freq, T),\n",
    "                               mode=\"bilinear\", align_corners=False).squeeze(1)     # (B,F,T)\n",
    "    return (10**matched).clamp_min(1e-8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167db19f",
   "metadata": {},
   "source": [
    "### Checkpoint helpers for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckpt(model: nn.Module, path: str, cfg: STFTCfg):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    with open(path + \".json\", \"w\") as f:\n",
    "        f.write(cfg.to_json())\n",
    "\n",
    "def load_ckpt(path: str, device: str = None, use_film: bool = False, fallback: STFTCfg = STFTCfg()) -> Tuple[nn.Module, STFTCfg]:\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    cfg_path = path + \".json\"\n",
    "    cfg = fallback\n",
    "    if os.path.exists(cfg_path):\n",
    "        with open(cfg_path) as f:\n",
    "            cfg = STFTCfg.from_json(f.read())\n",
    "\n",
    "    model = PhaseDiffPredictionModel(n_fft=cfg.n_fft, hop_length=cfg.hop, use_film=use_film).to(device)\n",
    "    sd = torch.load(path, map_location=device)\n",
    "    if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "        sd = sd[\"state_dict\"]\n",
    "    model.load_state_dict(sd, strict=False)\n",
    "    model.eval()\n",
    "    return model, cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbd372",
   "metadata": {},
   "source": [
    "### audio I/O helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5ffdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path: str, target_sr: int) -> Tuple[torch.Tensor, int]:\n",
    "    \"\"\"\n",
    "    Returns (wav, sr) with wav shaped (1, T), float32, mono, resampled to target_sr.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wav, sr = torchaudio.load(path, backend=\"soundfile\")\n",
    "    except Exception:\n",
    "        import soundfile as sf\n",
    "        data, sr = sf.read(path, always_2d=True)\n",
    "        wav = torch.from_numpy(data).T.contiguous()\n",
    "\n",
    "    wav = wav.float()\n",
    "    if wav.size(0) > 1:\n",
    "        wav = wav.mean(dim=0, keepdim=True)\n",
    "    if sr != target_sr:\n",
    "        wav = torchaudio.functional.resample(wav, sr, target_sr)\n",
    "        sr = target_sr\n",
    "    return wav, sr\n",
    "\n",
    "@torch.no_grad()\n",
    "def match_rms(y: torch.Tensor, ref: torch.Tensor, eps=1e-8) -> torch.Tensor:\n",
    "    if y.ndim == 1: y = y.unsqueeze(0)\n",
    "    if ref.ndim == 1: ref = ref.unsqueeze(0)\n",
    "    rms_y   = torch.sqrt((y**2).mean(dim=-1, keepdim=True) + eps)\n",
    "    rms_ref = torch.sqrt((ref**2).mean(dim=-1, keepdim=True) + eps)\n",
    "    return torch.clamp(y * (rms_ref / rms_y), -1.0, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ecb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data bootstrap utilities  ---\n",
    "def load_subset_paths(paths_txt=\"subset_paths.txt\", data_dirs=None, exts=(\".wav\",\".flac\",\".mp3\",\".ogg\")):\n",
    "    \"\"\"\n",
    "    Load persisted file list if available; otherwise scan once and persist.\n",
    "    Returns: list[str] of absolute or relative paths.\n",
    "    \"\"\"\n",
    "    if os.path.exists(paths_txt):\n",
    "        with open(paths_txt) as f:\n",
    "            subset_paths = [ln.strip() for ln in f if ln.strip()]\n",
    "        print(f\"Loaded {len(subset_paths)} paths from {paths_txt}.\")\n",
    "        return subset_paths\n",
    "\n",
    "    # we just scan once\n",
    "    if data_dirs is None:\n",
    "        data_dirs = [\"./ears\", \"./libritts\", \"./vctk\", \"./data\"]\n",
    "\n",
    "    subset_paths = []\n",
    "    for root in data_dirs:\n",
    "        if not os.path.isdir(root):\n",
    "            continue\n",
    "        for ext in exts:\n",
    "            subset_paths += glob.glob(os.path.join(root, f\"**/*{ext}\"), recursive=True)\n",
    "\n",
    "    subset_paths = [p for p in subset_paths if os.path.getsize(p) > 0]\n",
    "    assert subset_paths, f\"No audio found. Edit data_dirs={data_dirs} or place a {paths_txt}.\"\n",
    "\n",
    "    with open(paths_txt, \"w\") as f:\n",
    "        f.write(\"\\n\".join(subset_paths))\n",
    "    print(f\"Scanned and saved {len(subset_paths)} paths to {paths_txt}.\")\n",
    "    return subset_paths\n",
    "\n",
    "\n",
    "class ListAudioDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Mono + resample + random crop, like your training cell.\n",
    "    Returns float32 tensors shaped (N,) at target sr.\n",
    "    \"\"\"\n",
    "    def __init__(self, paths, sr=16000, seconds=3):\n",
    "        self.paths = paths\n",
    "        self.sr = sr\n",
    "        self.samples = int(seconds * sr)\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        wav, sr = torchaudio.load(p)               # (C, L)\n",
    "        wav = wav.mean(0, keepdim=True)            # mono\n",
    "        if sr != self.sr:\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
    "        if wav.shape[-1] < self.samples:           # pad by repetition if too short\n",
    "            reps = (self.samples + wav.shape[-1] - 1) // wav.shape[-1]\n",
    "            wav = wav.repeat(1, reps)\n",
    "        start = random.randint(0, wav.shape[-1] - self.samples)\n",
    "        return wav[:, start:start+self.samples].squeeze(0)   # (N,)\n",
    "\n",
    "def make_dataloader(subset_paths, *, sr=16000, seconds=3, batch_size=6, num_workers=0, shuffle=True, drop_last=True):\n",
    "    ds = ListAudioDataset(subset_paths, sr=sr, seconds=seconds)\n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    print(f\"DataLoader ready: {len(ds)} files → {len(dl)} batches\")\n",
    "    return dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Stretch-aware front-end helpers ----------------------------------------\n",
    "\n",
    "def _interp_time_linear_1d(x_1ft: torch.Tensor, new_T: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x_1ft: (1, F, T)  (float)\n",
    "    returns: (1, F, new_T)\n",
    "    \"\"\"\n",
    "    return tF.interpolate(\n",
    "        x_1ft.unsqueeze(0), size=(x_1ft.size(1), new_T),\n",
    "        mode=\"bilinear\", align_corners=False\n",
    "    ).squeeze(0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def resample_logmag_per_item(mag: torch.Tensor, z: torch.Tensor) -> list:\n",
    "    \"\"\"\n",
    "    mag: (B, F, T) linear magnitude\n",
    "    z  : (B,) stretch factors\n",
    "    returns: list of (mag_z_log, T_b) with time length T_b = round(z_b * T)\n",
    "    \"\"\"\n",
    "    B, F, T = mag.shape\n",
    "    out = []\n",
    "    logmag = mag.clamp_min(1e-8).log10()  # (B,F,T)\n",
    "    for b in range(B):\n",
    "        zb = float(z[b].item())\n",
    "        Tb = max(1, int(round(T * zb)))\n",
    "        m  = _interp_time_linear_1d(logmag[b:b+1], Tb)  # (1,F,Tb)\n",
    "        out.append((m.squeeze(0), Tb))\n",
    "    return out  # list of (F, Tb) in log-domain\n",
    "\n",
    "def sinusoidal_positional_embedding(T: int, dim: int, device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Classic transformer-style sin/cos PE evaluated on indices 0..T-1 (float ok).\n",
    "    returns: (dim, T)\n",
    "    \"\"\"\n",
    "    assert dim % 2 == 0, \"dim must be even\"\n",
    "    pos = torch.arange(T, device=device, dtype=torch.float32)          # (T,)\n",
    "    i = torch.arange(dim // 2, device=device, dtype=torch.float32)\n",
    "    inv_freq = 1.0 / (10000 ** (2 * i / dim))\n",
    "    angles = pos[None, :] * inv_freq[:, None]                           # (dim/2, T)\n",
    "    pe = torch.cat([torch.sin(angles), torch.cos(angles)], dim=0)       # (dim, T)\n",
    "    return pe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b43f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_stretch_features(\n",
    "    mag: torch.Tensor, z: torch.Tensor, *,\n",
    "    freq_fold_size: int = 2, pos_dim: int = 16,\n",
    "    sampler=None,\n",
    "    pe_module=None,\n",
    "    pe_concat_fixed: bool = False,\n",
    "    pe_jitter: float = 0.0,\n",
    "    pe_extrap_frac: float = 0.0,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      feats: (B, C_in, F_fold, T_max) with C_in = freq_fold_size + pos_dim + 1\n",
    "      mag_z: (B, F, T_max)\n",
    "    \"\"\"\n",
    "    B, F, T = mag.shape\n",
    "    device = mag.device\n",
    "    if sampler is None:\n",
    "        sampler = Sampler1D(\"linear\")\n",
    "\n",
    "    # 1) per-item resample log-magnitude to Tb approx z*T \n",
    "    logmag = mag.clamp_min(1e-8).log10()  # (B,F,T)\n",
    "    items = []\n",
    "    T_max = 0\n",
    "    for b in range(B):\n",
    "        Tb = max(1, int(round(float(z[b])*T)))\n",
    "        x  = logmag[b:b+1].unsqueeze(1)           # (1,1,F,T)\n",
    "        x_ = sampler(x, Tb).squeeze(1)            # (1,F,Tb) -> (1,F,Tb)\n",
    "        items.append(x_.squeeze(0))               # (F,Tb)\n",
    "        T_max = max(T_max, Tb)\n",
    "\n",
    "    feats_list, mags_lin = [], []\n",
    "    for b in range(B):\n",
    "        m_log = items[b]                          # (F,Tb)\n",
    "        Tb = m_log.size(1)\n",
    "\n",
    "        # here wedrop Nyquist for even fold and fold into channels\n",
    "        m_log = m_log[:-1, :]                     # (F-1,Tb)\n",
    "        F_use = m_log.size(0)\n",
    "        m_in = m_log.unsqueeze(0).unsqueeze(0)    # (1,1,F-1,Tb)\n",
    "\n",
    "        pad_f = (freq_fold_size - (F_use % freq_fold_size)) % freq_fold_size\n",
    "        if pad_f: m_in = tF.pad(m_in, (0,0,0,pad_f))\n",
    "        m_fold = rearrange(m_in, 'b c (f n) t -> b n f t', n=freq_fold_size)  # (1,n,F_fold,Tb)\n",
    "\n",
    "        # 2) positional embedding channel(s)\n",
    "        if pe_module is not None:\n",
    "            pe_learn = pe_module(T_out=Tb, device=device, jitter=pe_jitter, extrap_frac=pe_extrap_frac)  # (dim,Tb)\n",
    "            pe_list = [pe_learn]\n",
    "            if pe_concat_fixed:\n",
    "                pe_fixed = sinusoidal_positional_embedding(Tb, pos_dim//2, device)\n",
    "                pe_learn = pe_learn[:pos_dim - pe_fixed.size(0), :] if pos_dim > pe_fixed.size(0) else pe_learn\n",
    "                pe_list = [pe_fixed, pe_learn]\n",
    "            pe = torch.cat(pe_list, dim=0)[:pos_dim, :]    # (pos_dim, Tb)\n",
    "        else:\n",
    "            pe = sinusoidal_positional_embedding(Tb, pos_dim, device)\n",
    "\n",
    "        pe = pe.unsqueeze(0).unsqueeze(2)                  # (1,pos_dim,1,Tb)\n",
    "\n",
    "        # 3) z-map channel\n",
    "        z_map = z[b:b+1].view(1,1,1,1).expand(1,1,1,Tb)\n",
    "\n",
    "        # time-pad to T_max\n",
    "        if Tb < T_max:\n",
    "            pad_t = (0, T_max - Tb)\n",
    "            m_fold = tF.pad(m_fold, pad_t)\n",
    "            pe     = tF.pad(pe, pad_t)\n",
    "            z_map  = tF.pad(z_map, pad_t)\n",
    "\n",
    "        feats_list.append(torch.cat([m_fold, pe, z_map], dim=1))  # (1, n+pos_dim+1, F_fold, T_max)\n",
    "\n",
    "        # we keep full-F magnitude (linear) for inversion\n",
    "        full_log = items[b]              # (F,Tb) before Nyquist drop\n",
    "        if Tb < T_max:\n",
    "            full_log = tF.pad(full_log.unsqueeze(0), (0, T_max - Tb)).squeeze(0)\n",
    "        mags_lin.append((10.0**full_log).clamp_min(1e-8))\n",
    "\n",
    "    feats = torch.cat(feats_list, dim=0)       # (B, C_in, F_fold, T_max)\n",
    "    mag_z = torch.stack(mags_lin, dim=0)       # (B, F, T_max)\n",
    "    return feats, mag_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StretchAwareModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Consumes features from build_stretch_features:\n",
    "      feats: (B, C_in, F_fold, T_max)  where C_in = freq_fold_size + pos_dim + 1\n",
    "    Predicts (fpd, bpd) at unfolded F sizes to match mag_z for inversion.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_fft: int, hop_length: int,\n",
    "                 in_channels: int,          # freq_fold_size + pos_dim + 1\n",
    "                 freq_fold_size: int = 2, bn: bool = False):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.freq_fold_size = freq_fold_size\n",
    "\n",
    "\n",
    "        self.stem = Stem(in_ch=in_channels, bn=bn)\n",
    "        self.body = Body(bn=bn, use_film=False)   \n",
    "        self.head = Head(out_per_target=freq_fold_size)\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "    @staticmethod\n",
    "    def _init(m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Conv1d, nn.Linear)):\n",
    "            nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "            if m.bias is not None: nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, feats: torch.Tensor, mag_for_unfold: torch.Tensor):\n",
    "        \"\"\"\n",
    "        feats: (B, C_in, F_fold, T)    from build_stretch_features\n",
    "        mag_for_unfold: (B, F, T)      full-F linear magnitude for inversion\n",
    "        Returns: fpd, bpd shaped to match (F-1, T) and (F, T)\n",
    "        \"\"\"\n",
    "        z0 = self.stem(feats)                       # (B, 10, F_fold, T)\n",
    "        z1, _ = self.body(z0)                       # (B, 10, F_fold, T)\n",
    "        z  = torch.cat([z0, z1], dim=1)             # (B, 20, F_fold, T)\n",
    "        bpd_fold, fpd_fold = self.head(z)           # (B, n, F_fold, T) each\n",
    "\n",
    "        # Unfold back in frequency\n",
    "        bpd = rearrange(bpd_fold, 'b n f t -> b (f n) t')   # (B, F_flat, T)\n",
    "        fpd = rearrange(fpd_fold, 'b n f t -> b (f n) t')\n",
    "\n",
    "        F_in  = mag_for_unfold.size(1)              \n",
    "        F_fpd = F_in - 1\n",
    "\n",
    "       \n",
    "        if bpd.size(1) < F_in:  bpd = torch.cat([bpd, bpd[:, -1:, :]], dim=1)\n",
    "        if bpd.size(1) > F_in:  bpd = bpd[:, :F_in, :]\n",
    "        if fpd.size(1) < F_fpd: fpd = torch.cat([fpd, fpd[:, -1:, :]], dim=1)\n",
    "        if fpd.size(1) > F_fpd: fpd = fpd[:, :F_fpd, :]\n",
    "        return fpd, bpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pv_stretch_waveform(wav: torch.Tensor, z: float, n_fft: int, hop: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Minimal phase-vocoder (batch-safe), implemented in plain PyTorch.\n",
    "    - wav: (B, N)\n",
    "    - z: stretch factor (>1 => longer/slower)\n",
    "    - returns: (B, ~z*N)\n",
    "    \"\"\"\n",
    "    device = wav.device\n",
    "    stft = CausalSTFT(n_fft, hop, n_fft).to(device)\n",
    "    istft = CausalISTFT(n_fft, hop, n_fft).to(device)\n",
    "\n",
    "    # Analysis STFT: (B, F, T) complex\n",
    "    S = stft(wav)\n",
    "    mag = S.abs()                # (B, F, T)\n",
    "    phase = torch.angle(S)       # (B, F, T)\n",
    "    B, F, T = S.shape\n",
    "\n",
    "    # Synthesis frame count\n",
    "    T_out = max(1, int(math.ceil(T * z)))\n",
    "\n",
    "    # omega_k * hop (phase advance per bin per hop)\n",
    "    k = torch.arange(F, device=device).view(1, F, 1)\n",
    "    phase_advance = (2.0 * math.pi * hop * k / n_fft)      # (1, F, 1)\n",
    "\n",
    "    # Init accumulator with first analysis phase\n",
    "    phase_acc = phase[..., 0:1].clone()                    # (B, F, 1)\n",
    "\n",
    "    # Output buffers\n",
    "    mag_out   = torch.zeros(B, F, T_out, device=device)\n",
    "    phase_out = torch.zeros(B, F, T_out, device=device)\n",
    "\n",
    "    # Helper to wrap to [-pi, pi]\n",
    "    def princarg(x):  \n",
    "        return torch.remainder(x + math.pi, 2*math.pi) - math.pi\n",
    "\n",
    "    # Main PV loop (vectorized over batch + freq, iterates over output time)\n",
    "    for t_out in range(T_out):\n",
    "        t_src = t_out / z\n",
    "        t0 = int(math.floor(t_src))\n",
    "        t1 = min(t0 + 1, T - 1)\n",
    "        frac = t_src - t0\n",
    "\n",
    "        # Linear mag interpolation\n",
    "        m0 = mag[..., t0]            # (B, F)\n",
    "        m1 = mag[..., t1]            # (B, F)\n",
    "        m  = (1.0 - frac) * m0 + frac * m1\n",
    "\n",
    "\n",
    "        # delta_phi = princarg(phi[t1] - phi[t0] - phase_advance)\n",
    "        dphi = princarg(phase[..., t1] - phase[..., t0] - phase_advance.squeeze(-1))\n",
    "\n",
    "        # Accumulate phase: advance one hop plus a fraction of delt phi\n",
    "        phase_acc = phase_acc + phase_advance + frac * dphi.unsqueeze(-1)   # we keep last dim=1\n",
    "\n",
    "        mag_out[..., t_out]   = m\n",
    "        phase_out[..., t_out] = phase_acc.squeeze(-1)\n",
    "\n",
    "    # Recompose complex STFT and invert\n",
    "    S_out = mag_out * torch.exp(1j * phase_out)   # (B, F, T_out)\n",
    "    y = istft(S_out)                               # (B, ~z*N)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f009d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Angle-safe helpers ------------------------------------------------------\n",
    "\n",
    "def _wrap_pi(x: torch.Tensor) -> torch.Tensor:\n",
    "    # wrap to (-pi, pi]\n",
    "    return torch.remainder(x + math.pi, 2 * math.pi) - math.pi\n",
    "\n",
    "@torch.no_grad()\n",
    "def angle_time_interpolate(x: torch.Tensor, new_T: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Angle tensor (B, F, T) or (B, Fm1, T) -> resize along time to new_T using\n",
    "    complex projection to avoid branch cuts.\n",
    "    \"\"\"\n",
    "    B, F, T = x.shape\n",
    "    # represent on unit circle and interpolate real/imag separately\n",
    "    c = torch.cos(x)\n",
    "    s = torch.sin(x)\n",
    "    c = tF.interpolate(c, size=new_T, mode=\"linear\", align_corners=False)\n",
    "    s = tF.interpolate(s, size=new_T, mode=\"linear\", align_corners=False)\n",
    "    ang = torch.atan2(s, c)\n",
    "    return _wrap_pi(ang)\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_pv_targets_per_batch(wav: torch.Tensor, z: torch.Tensor,\n",
    "                                 n_fft: int, hop: int, stft_mod: CausalSTFT):\n",
    "    \"\"\"\n",
    "    wav: (B, N)\n",
    "    z  : (B,)\n",
    "    Returns per-batch lists (one per item) of:\n",
    "      - y_ref (stretched waveform)\n",
    "      - (mag_ref, fpd_ref, bpd_ref) tensors\n",
    "    Lengths differ per item; we will align later.\n",
    "    \"\"\"\n",
    "    B = wav.size(0)\n",
    "    y_refs = []\n",
    "    for b in range(B):\n",
    "        y_refs.append(pv_stretch_waveform(wav[b:b+1], float(z[b].item()), n_fft, hop))  # (1, N')\n",
    "    # batch pad to common length for a single STFT call\n",
    "    Lmax = max(y.shape[-1] for y in y_refs)\n",
    "    y_pad = torch.zeros(B, Lmax, device=wav.device)\n",
    "    for b,y in enumerate(y_refs):\n",
    "        y_pad[b, :y.shape[-1]] = y.squeeze(0)\n",
    "\n",
    "    mag_ref, fpd_ref, bpd_ref = compute_mag_fpd_bpd(y_pad, n_fft, hop, stft_mod)  # (B,F,T'),(B,F-1,T'),(B,F,T')\n",
    "    return y_refs, mag_ref, fpd_ref, bpd_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb405f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1847 paths from subset_paths.txt.\n",
      "DataLoader ready: 1847 files → 307 batches\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def mrstft_loss(y_hat: torch.Tensor, y_ref: torch.Tensor, n_ffts=(512,1024,2048), hops=(80,160,320)) -> torch.Tensor:\n",
    "    loss = 0.0\n",
    "    for n,h in zip(n_ffts, hops):\n",
    "        stft = CausalSTFT(n, h, n).to(y_hat.device)\n",
    "        Yh = stft(y_hat).abs()\n",
    "        Yr = stft(y_ref).abs()\n",
    "        # log-mag L1 + spectral convergence\n",
    "        loss += (Yh.log1p() - Yr.log1p()).abs().mean()\n",
    "        loss += (Yh - Yr).norm() / (Yr.norm() + 1e-8)\n",
    "    return loss / len(n_ffts)\n",
    "\n",
    "def si_sdr(ref: torch.Tensor, est: torch.Tensor, eps=1e-8) -> torch.Tensor:\n",
    "    ref = ref - ref.mean(dim=-1, keepdim=True)\n",
    "    est = est - est.mean(dim=-1, keepdim=True)\n",
    "    alpha = (est*ref).sum(dim=-1, keepdim=True) / (ref.pow(2).sum(dim=-1, keepdim=True)+eps)\n",
    "    target = alpha * ref\n",
    "    noise = est - target\n",
    "    return 10.0 * torch.log10((target.pow(2).sum(dim=-1)+eps)/(noise.pow(2).sum(dim=-1)+eps))\n",
    "\n",
    "# --- Data  ------------------------------------------------------\n",
    "set_seed(7)\n",
    "cfg = STFTCfg(sr=16000, n_fft=512, hop=80)\n",
    "stft = CausalSTFT(cfg.n_fft, cfg.hop, cfg.n_fft).to(device)\n",
    "\n",
    "subset_paths = load_subset_paths(\"subset_paths.txt\")\n",
    "dl = make_dataloader(subset_paths, sr=cfg.sr, seconds=3, batch_size=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b1992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
